# Optimizing the Performance


## ğŸ“– Table of Contents
1. [I. Metrics Collection](#i-metrics-collection)
2. [II. Rewriting Manifests](#ii-rewriting-manifests)



## I. Metrics Collection
NhÆ° Ä‘Ã£ biáº¿t metadata file theo dÃµi cÃ¡c cá»™t Ä‘á»ƒ pruning/query optimization => CÃ³ thá»ƒ háº¡n cháº¿ cÃ¡ch theo dÃµi cÃ¡c cá»™t.

```sql
ALTER TABLE catalog.db.students SET TBLPROPERTIES (
    'write.metadata.metrics.column.col1'='none',
    'write.metadata.metrics.column.col2'='full',
    'write.metadata.metrics.column.col3'='counts',
    'write.metadata.metrics.column.col4'='truncate(16)',
);
```

* `none`: Ko theo dÃµi
* `full`: Theo dÃµi Ä‘á»§
* `counts`: Theo dÃµi cÃ¡c chá»‰ sá»‘ nhÆ° Ä‘áº¿m null values, distinct values, total values (ko quan tÃ¢m min, max)
* `truncate`: Theo dÃµi n kÃ­ tá»±

----

## II. Rewriting Manifests
#### 1. LÃ­ do
- NhÆ° Ä‘Ã£ biáº¿t manifest file chá»©a path cá»§a cÃ¡c datafile.
- `Váº¥n Ä‘á»:` 1 manifest file quáº£n lÃ½ quÃ¡ Ã­t datafile thÃ¬ sao? tá»‘n cÃ´ng IO Ä‘á»c.
- `Giáº£i phÃ¡p:` 1 manifest quáº£n lÃ½ nhiá»u datafile hÆ¡n. Háº¡n cháº¿ tá»‘n cÃ´ng Ä‘á»c metadata.

#### 2. Code
```sql
CALL catalog.system.rewrite_manifests('MyTable')
```

* `rewrite_manifests`: hÃ m rewrite láº¡i manifest file.

Trong trÆ°á»ng há»£p gáº·p váº¥n Ä‘á» vá» memory (Spark executor OOM), cÃ³ thá»ƒ táº¯t Spark caching báº±ng cÃ¡ch truyá»n thÃªm tham sá»‘ false:

```sql
CALL catalog.system.rewrite_manifests('MyTable', false)
```

#### 3. LÆ°u Ã½
- NÃªn rewrite datafile trÆ°á»›c rá»“i má»›i nghÄ© rewrite manifest file Ä‘á»ƒ trÃ¡nh ko tá»‘i Æ°u.

----


## III. Optimizing Storage
Snapshot Ä‘Æ°á»£c sinh ra khi cÃ³ dá»¯ liá»‡u má»›i insert. Náº¿u ko clean sáº½ phÃ¬nh Ã¡c.

#### 1. Expire Snapshots

```sql
CALL catalog.system.expire_snapshots(
  'MyTable',
  TIMESTAMP '2023-02-01 00:00:00.000',
  100
)
```

Ã nghÄ©a:
* XoÃ¡ snapshot â‰¤ timestamp
* NhÆ°ng váº«n giá»¯ Ã­t nháº¥t 100 snapshot gáº§n nháº¥t

```sql
CALL catalog.system.expire_snapshots(
  table => 'MyTable',
  snapshot_ids => ARRAY(53)
)
```


| Tham sá»‘                  | Ã nghÄ©a                                         |
| ------------------------ | ----------------------------------------------- |
| `table`                  | Table cáº§n dá»n                                   |
| `older_than`             | XoÃ¡ snapshot trÆ°á»›c má»‘c thá»i gian                |
| `retain_last`            | Sá»‘ snapshot tá»‘i thiá»ƒu giá»¯ láº¡i                   |
| `snapshot_ids`           | Snapshot chá»‰ Ä‘á»‹nh                               |
| `max_concurrent_deletes` | Sá»‘ thread xoÃ¡ file                              |
| `stream_results`         | Stream danh sÃ¡ch file xoÃ¡ vá» driver (trÃ¡nh OOM) |



#### 2. Orphan files
Trong quÃ¡ trÃ¬nh ingest dá»± liá»‡u lá»¡ failed job, má»™t sá»‘ file sáº½ bá»‹ má»“ cÃ´i. NhÆ°ng file má»“ cÃ´i láº¡i ko Ä‘Æ°á»£c trá» vÃ o snapshot nÃ o. NÃªn pháº£i tá»± dá»n.

```sql
CALL catalog.system.remove_orphan_files(table => 'MyTable')
```

| Tham sá»‘                  | Ã nghÄ©a                 |
| ------------------------ | ----------------------- |
| `table`                  | Table cáº§n dá»n           |
| `older_than`             | Chá»‰ xoÃ¡ file cÅ© hÆ¡n má»‘c |
| `location`               | Directory cáº§n scan      |
| `dry_run`                | Chá»‰ list, khÃ´ng xoÃ¡     |
| `max_concurrent_deletes` | Thread xoÃ¡              |


## IV. Write Distribution Mode
Trong quÃ¡ trÃ¬nh ghi song song tá»« cÃ¡c PP (Parallel Processing) sáº½ táº¡o ra ráº¥t nhiá»u file do phÃ¢n tasks theo cÆ¡ cháº¿ Spark.
Viá»‡c nÃ y sáº½ áº£nh hÆ°á»Ÿng viá»‡c lÆ°u trá»¯ vÃ  truy váº¥n sau nÃ y.
Ice Berg cho table Ä‘Æ°á»£c set property Ä‘á»ƒ khi Spark xá»­ lÃ½ xong yÃªu cáº§u lÃ m thÃªm bÆ°á»›c shuffle => ra luáº­t Ä‘á»ƒ cÃ¡c PP shuffle cÃ³ lá»£i nháº¥t

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
    'write.distribution-mode'='hash',
    'write.delete.distribution-mode'='none',
    'write.update.distribution-mode'='range',
    'write.merge.distribution-mode'='hash',
);
```

| Operation | Mode  | LÃ½ do                 |
| --------- | ----- | --------------------- |
| INSERT    | hash  | Ãt file, á»•n Ä‘á»‹nh      |
| DELETE    | none  | TrÃ¡nh shuffle         |
| UPDATE    | range | File gá»n, query nhanh |
| MERGE     | hash  | CÃ¢n báº±ng hiá»‡u nÄƒng    |


-----

## IV. Object Storage
CÃ¡c Object Storage trÃ´ng giá»‘ng nhÆ° tá»• chá»©c theo Ä‘Æ°á»ng dáº«n thÆ° má»¥c.

Náº¿u nhiá»u request song song truy cáº­p cÃ¡c file **cÃ¹ng má»™t prefix**
â†’ cÃ³ thá»ƒ gÃ¢y ngháº½n object storage.

```
s3://bucket/database/table/field=value1/datafile1.parquet
s3://bucket/database/table/field=value1/datafile2.parquet
s3://bucket/database/table/field=value1/datafile3.parquet
```

Iceberg cÃ³ setting Ä‘á»ƒ **Ä‘Ã¡nh hash vÃ o prefix**, giÃºp cÃ¡c file trong cÃ¹ng partition Ä‘Æ°á»£c phÃ¢n tÃ¡n ra nhiá»u prefix khÃ¡c nhau:

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
  'write.object-storage.enabled' = true
);
```

Khi Ä‘Ã³ layout váº­t lÃ½ sáº½ nhÆ° sau:

```
s3://bucket/4809098/database/table/field=value1/datafile1.parquet
s3://bucket/5840329/database/table/field=value1/datafile2.parquet
s3://bucket/2342344/database/table/field=value1/datafile3.parquet
```

ğŸ‘‰ Nhá» váº­y, cÃ¡c request Ä‘Æ°á»£c **chia Ä‘á»u**, trÃ¡nh ngháº½n do quÃ¡ nhiá»u request dá»“n vÃ o cÃ¹ng má»™t prefix.


ğŸ‘ **Ráº¥t tá»‘t rá»“i â€” Ä‘Ãºng báº£n cháº¥t ~95%**.
MÃ¬nh chá»‰ **chá»‰nh nháº¹ vÃ i chá»— cho chuáº©n thuáº­t ngá»¯ vÃ  logic**, khÃ´ng thÃªm Ã½ má»›i nhÃ©.

---

## V. Bloom Filter

Bloom filter lÃ  metadata giÃºp kiá»ƒm tra nhanh má»™t datafile cÃ³ thá»ƒ chá»©a giÃ¡ trá»‹ A hay khÃ´ng thÃ´ng qua má»™t dÃ£y bit (0, 1).

* Náº¿u Bloom filter nÃ³i khÃ´ng cÃ³ â†’ cháº¯c cháº¯n khÃ´ng cÃ³
* Náº¿u nÃ³i cÃ³ thá»ƒ cÃ³ â†’ chÆ°a cháº¯c, váº«n pháº£i scan file

---

### CÆ¡ cháº¿

Ban Ä‘áº§u, Bloom filter lÃ  má»™t dÃ£y bit toÃ n 0:

```
A = [0 0 0 0 0 0 0 0 0 0]
```

Giáº£ sá»­ datafile cÃ³ cÃ¡c `user_id`:

```
[12, 25, 88]
```

---

**Insert dá»¯ liá»‡u**

* `Hash(12)` â†’ vá»‹ trÃ­ 3 â†’ báº­t bit 3

```
A = [0 0 0 1 0 0 0 0 0 0]
```

* `Hash(25)` â†’ vá»‹ trÃ­ 7 â†’ báº­t bit 7

```
A = [0 0 0 1 0 0 0 1 0 0]
```

* `Hash(88)` â†’ vá»‹ trÃ­ 3 â†’ trÃ¹ng â†’ bit Ä‘Ã£ báº­t, giá»¯ nguyÃªn

```
A = [0 0 0 1 0 0 0 1 0 0]
```

ğŸ‘‰ Bloom filter **chá»‰ báº­t bit**, khÃ´ng lÆ°u giÃ¡ trá»‹ tháº­t.

---

### Khi ngÆ°á»i dÃ¹ng query

* `user_id = 25`
  â†’ `Hash(25)` â†’ vá»‹ trÃ­ 7 â†’ bit = 1
  â†’ cÃ³ thá»ƒ cÃ³ â†’ scan file

* `user_id = 99`
  â†’ `Hash(99)` â†’ vá»‹ trÃ­ 4 â†’ bit = 0
  â†’ cháº¯c cháº¯n khÃ´ng cÃ³ â†’ skip file

---

### LÆ°u Ã½ (trade-off)

* Náº¿u **dá»¯ liá»‡u nhiá»u**, **cardinality cao**
* NhÆ°ng **dÃ£y bit quÃ¡ ngáº¯n**

ğŸ‘‰ Dá»… xáº£y ra **false positive** (Ä‘á»¥ng hash)
ğŸ‘‰ Tá»‘n thÃªm:

* Metadata (Bloom filter)
* Má»™t bÆ°á»›c check trÆ°á»›c khi Ä‘á»c file

```sql
ALTER TABLE catalog.MyTable SET TBLPROPERTIES (
  'write.parquet.bloom-filter-enabled.column.col1'= true,
  'write.parquet.bloom-filter-max-bytes'= 1048576
);
```
