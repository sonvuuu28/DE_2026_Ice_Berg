# Optimizing the Performance

## ğŸ“– Table of Contents
1. [I. Compaction](#i-compaction)  
2. [IV. File Size & Row Group Size cá»§a parquet](#iv-file-size--row-group-size)  
3. [V. Partial Progress](#v-partial-progress)  
4. [VII. Hidden Partition](#vii-hidden-partition)  
5. [VIII. Partition Evolution](#viii-partition-evolution)

## I. Compaction
Gom cÃ¡c data files nhá» vá» 1 file lá»›n Ä‘á»ƒ giáº£m thiá»ƒu thao tÃ¡c Ä‘á»c, má»Ÿ, Ä‘Ã³ng.
![alt text](images/6.png)

**Quick Note for Streaming Tasks:**
- Ãp dá»¥ng compaction trong khung 1 giá». 
- Ãp dá»¥ng strategy binpack.
- Target file size ~ 1GB
- Báº­t partial progress commit
- CÃ³ thá»ƒ káº¿t há»£p airflow Ä‘á»ƒ auto compaction

**Quick Note for Batching Tasks:**
- Sort data rá»“i má»›i insert
- Ãp dá»¥ng strategy sort/z-order phá»¥ thuá»™c vÃ o xu hÆ°á»›ng query cáº£u end user.

![alt text](images/chap4_3.png)

## II. Demo code
```spark
Table table =  catalog.loadTable("myTable");
SparkActions
.get()
.rewriteDataFiles(table)
.option("rewrite-job-order", "files-desc")
.execute();
```
![alt text](images/chap4_1.png)


## III. CÃ¡c phÆ°Æ¡ng thá»©c
### Strategies (Methods)

| Method  | MÃ´ táº£ |
|--------|------|
| sort   | Rewrite data files vÃ  **sort theo má»™t hoáº·c nhiá»u cá»™t** theo thá»© tá»± Æ°u tiÃªn |
| zOrder | Rewrite data files vÃ  **Z-order sort** theo nhiá»u cá»™t vá»›i **trá»ng sá»‘ ngang nhau** |
| filter | Chá»‰ rewrite **nhá»¯ng file thá»a Ä‘iá»u kiá»‡n** (expression) |
| option | Set **má»™t option Ä‘Æ¡n láº»** |
| options| Set **nhiá»u option cÃ¹ng lÃºc** (map) |

- strategy => 'binpack': gom files nhá» thÃ nh file bá»± => Ráº¥t nhanh chÃ³ng
- NhÆ°ng náº¿u dÃ¹ng 'sort/z-Order' nÃ³ sáº½ compact theo thá»© tá»± 1/n cá»™t nÃ o Ä‘Ã³ => sau query nhanh hÆ¡n vÃ¬ cÃ¹ng giÃ¡ trá»‹ náº±m háº¿t á»Ÿ 1 file, nhÆ°ng thá»i gian gom khÃ¡ lÃ¢u.
- Sort: sáº¯p cá»™t A theo thá»© tá»±, B sáº¯p theo thá»© tá»±, C, D,...
- Z-Order: Sáº¯p cá»™t Z-order sáº½ nhÃ³m:

(1,1),(1,2),(2,1),(2,2)

rá»“i tá»›i (1,3),(2,3)...

| CÃ¡c loáº¡i compaction | CÃ¡ch thá»©c | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c Ä‘iá»ƒm |
|---------------------|-----------|---------|------------|
| binpack | Gom cÃ¡c file nhá» thuáº§n | Nhanh gá»n láº¹ => há»£p streaming | Ko tá»‘i Æ°u cho heavy query |
| Sort | Sort tá»«ng cá»™t tá»«ng cá»™t, rá»“i má»›i gom file | PhÃ¹ há»£p cho heavy query | QuÃ¡ trÃ¬nh gom máº¥t thá»i gian |
| Z-Order | Sort zigzag | PhÃ¹ há»£p cho heavy query | QuÃ¡ trÃ¬nh gom máº¥t thá»i gian hÆ¡n cáº£ Sort |

Z-Order sáº½ sort nhÆ° sau: (1,1), (1,2), (2,1), (2,2), rá»“i má»›i tá»›i (1,3), (2,3),...

![alt text](images/chap4_4.png)

Náº¿u há»i "Táº¥t cáº£ cáº§u thá»§ cá»§a Ä‘á»™i Lions cÃ³ tÃªn báº¯t Ä‘áº§u báº±ng chá»¯ A" thÃ¬ sort ok nháº¥t

Náº¿u há»i "Táº¥t cáº£ cáº§u thá»§ cá»§a NLF cÃ³ tÃªn báº¯t Ä‘áº§u báº±ng chá»¯ A" thÃ¬ z-Order ok nháº¥t (náº¿u sort dÃ nh cho cÃ¢u nÃ y, data row náº±m ráº£i rÃ¡c cÃ¡c file cÃ³ thá»ƒ quÃ©t háº¿t file)

=> Dá»±a vÃ o xu hÆ°á»›ng há»i Ä‘á»ƒ tá»• chá»©c Ä‘ata.

---

### Options
| Option | Ã nghÄ©a |
|------|--------|
| target-file-size-bytes | KÃ­ch thÆ°á»›c file output mong muá»‘n (default: **512MB**, láº¥y tá»« `write.target.file-size-bytes`) |
| max-concurrent-file-group-rewrites | Sá»‘ **file group tá»‘i Ä‘a** Ä‘Æ°á»£c rewrite **song song** |
| max-file-group-size-bytes | Giá»›i háº¡n size cá»§a **má»™t file group** Ä‘á»ƒ trÃ¡nh vÆ°á»£t memory cá»§a worker |
| partial-progress-enabled | Cho phÃ©p **commit tá»«ng pháº§n** trong khi compaction váº«n Ä‘ang cháº¡y |
| partial-progress-max-commits | Sá»‘ **commit tá»‘i Ä‘a** khi báº­t partial progress |
| rewrite-job-order | Thá»© tá»± rewrite file groups: `bytes-asc`, `bytes-desc`, `files-asc`, `files-desc`, `none` |

---

### rewrite-job-order Values
| Value | Ã nghÄ©a |
|-----|--------|
| bytes-asc | Rewrite group nhá» trÆ°á»›c |
| bytes-desc | Rewrite group lá»›n trÆ°á»›c |
| files-asc | Group Ã­t file trÆ°á»›c |
| files-desc | Group nhiá»u file trÆ°á»›c |
| none | KhÃ´ng Æ°u tiÃªn |


## IV. File Size & Row Group Size
**Filter query nhiá»u Æ°u tiÃªn chia nhiá»u group, full scan nhiá»u chia Ã­t group**

### 1. Parquet
Äá»‘i vá»›i Parquet cÃ³ row group size & file size:
- **Row group**: Ä‘Æ¡n vá»‹ Ä‘á»c nhá» nháº¥t, cÃ³ metadata riÃªng. 
- Query Engine skip theo **row group** ko pháº£i theo row.

Set up default:
- 4 row groups/file
- Row group: 128MB
- File size: 512MB

**LÆ°u Ã½:** NÃªn chia Ä‘á»u giá»¯a file size vÃ  row group Ä‘á»ƒ trÃ¡nh file cuá»‘i nhá» hÆ¡n.

### 2. So sÃ¡nh row groups
| Chiáº¿n lÆ°á»£c                             | Æ¯u Ä‘iá»ƒm                                                | NhÆ°á»£c Ä‘iá»ƒm                                                             |
| -------------------------------------- | ------------------------------------------------------ | ---------------------------------------------------------------------- |
| **Ãt row group**<br> | - File gá»n hÆ¡n<br>- Ãt metadata hÆ¡n<br>- Overhead tháº¥p | - Predicate pushdown kÃ©m<br>- Query filter pháº£i Ä‘á»c nhiá»u dá»¯ liá»‡u thá»«a |
| **Nhiá»u row group**<br> | - Predicate pushdown tá»‘t<br>- Query filter nhanh hÆ¡n   | - Metadata nhiá»u hÆ¡n<br>- Tá»‘n thá»i gian Ä‘á»c metadata                   |


**VÃ­ dá»¥:**
- File 1 GB chia lÃ m 8 row group hoáº·c 4 row group
- Khi lá»c cá»™t country tÃ¬m 'VN'
- Náº¿u Ã­t row group Ä‘á»¡ tá»‘n tgian Ä‘á»c nhiá»u metadata hÆ¡n
- NhÆ°ng nhiá»u row Ä‘á»c min/max á»Ÿ metadata Ä‘Ã£ cÃ³ thá»ƒ lá»c kha khÃ¡ row group

### 3. Setting parameters
![alt text](images/chap4_2.png)


## V. Partial Progress
Compact Ä‘Æ°á»£c nhiÃªu files nhá» (file group) commit, táº¡o snapshot má»›i luÃ´n trÃ¡nh out-of-mem vÃ  Ä‘áº£m báº£o lastest version Ä‘Æ°á»£c user sá»­ dá»¥ng

from III:
| Option | Ã nghÄ©a |
|-----|--------|
| partial-progress-enabled | Cho phÃ©p **commit tá»«ng pháº§n** trong khi compaction váº«n Ä‘ang cháº¡y |
| partial-progress-max-commits | Sá»‘ **commit tá»‘i Ä‘a** khi báº­t partial progress |


## VI. Code Example
cÃ³ 2 loáº¡i:
- Actions API (Java/Scala)
- Spark SQL

---

```sql
Table table = catalog.loadTable("myTable");
SparkActions
    .get()
    .rewriteDataFiles(table)
    .sort()
    .filter(Expressions.and(
    Expressions.greaterThanOrEqual("date", "2023-01-01"),
    Expressions.lessThanOrEqual("date", "2023-01-31")))
    .option("rewrite-job-order", "files-desc")
    .execute();
```

- rewriteDataFiles  : cháº¡y compaction (gá»™p datafile)
- sort()            : sort theo sort order cá»§a table (row-level)
- filter            : giá»›i háº¡n datafile cáº§n rewrite (trong manifest file cÃ³ trÆ°á»ng partition)
- rewrite-job-order : Æ°u tiÃªn group nhiá»u file rewrite trÆ°á»›c
- execute           : trigger Spark job + commit snapshot


---

```sql
CALL catalog.system.rewrite_data_files(
    table => 'musicians',
    strategy => 'binpack',
    where => 'genre = "rock"',
    options => map(
    'rewrite-job-order','bytes-asc',
    'target-file-size-bytes','1073741824', -- 1GB
    'max-file-group-size-bytes','10737418240' -- 10GB
    )
)
```
- rewriteDataFiles                  : cháº¡y compaction (gá»™p datafile)
- Binpack                           : chiáº¿n lÆ°á»£c máº·c Ä‘á»‹nh (ko sort)
- where = filter                    : xÃ©t trÆ°á»ng partition trong mainifest file
- rewrite-job-order +  bytes-asc    : Æ°u tiÃªn group nhiá»u file rewrite trÆ°á»›c
- target-file-size-byte             : file bá»± sau khi Ä‘Æ°á»£c gá»™p cÃ³ kÃ­ch thÆ°á»›c  
- max-file-group-size-bytes         : group file max kÃ­ch thÆ°á»›c 


```sql
CALL catalog.system.rewrite_data_files(
    table => 'nfl_teams',
    strategy => 'sort',
    sort_order => 'team ASC NULLS LAST, name ASC NULLS FIRST'
)
```


```sql
CALL catalog.system.rewrite_data_files(
    table => 'people',
    strategy => 'sort',
    sort_order => 'zorder(age,height)'
)  
```


## VII. Hidden Partition

CÃ³ **3** loáº¡i:

* TIME (`day`, `month`, `year`, `hour`)
* Truncate
* Bucket

---

#### 1. Time

Khi table Ä‘Æ°á»£c partition theo `month/year/day` trÃªn cá»™t timestamp.

Khi end user query:

```sql
WHERE timestamp ...
```

Iceberg sáº½:

* Dá»±a vÃ o metadata (manifest) Ä‘á»ƒ loáº¡i bá» cÃ¡c manifest file khÃ´ng náº±m trong khoáº£ng thá»i gian cáº§n tÃ¬m
* Sau Ä‘Ã³ má»›i scan dá»¯ liá»‡u chi tiáº¿t

---

#### 2. Truncate

Partition theo n kÃ½ tá»± (prefix) cá»§a cá»™t.
PhÃ¹ há»£p cho cÃ¡c trÆ°á»ng nhÆ° `name`.

---

#### 3. Bucket

* Partition table thÃ nh n bucket (xÃ´).
* NÃªn chá»n cá»™t cÃ³ cardinality cao.
* Ãp dá»¥ng hash + modulo.

```sql
PARTITIONED BY bucket(n, user_id)
```

**VÃ­ dá»¥**
User query:

```sql
WHERE user_id = X
```

Iceberg sáº½:

```
bucket_id = hash(user_id) % n
```

â†’ Chá»‰ quÃ©t 1 bucket, khÃ´ng quÃ©t `n-1` bucket cÃ²n láº¡i.

---


## VIII. Partition Evolution

#### 1. Äiá»ƒm yáº¿u Partition Hive-style (cÅ©)

Partition truyá»n thá»‘ng phá»¥ thuá»™c vÃ o `cáº¥u trÃºc thÆ° má»¥c váº­t lÃ½`, nÃªn khi thay Ä‘á»•i partition â‡’ báº¯t buá»™c rewrite toÃ n bá»™ table.

---

#### 2. Äiá»ƒm máº¡nh Partition Iceberg

* Partition (Iceberg) Ä‘Æ°á»£c theo dÃµi báº±ng `metadata`.
* Khi Ä‘á»•i partition:
  * KhÃ´ng rewrite data
  * Chá»‰ táº¡o metadata file má»›i Ã¡p dá»¥ng partition plan má»›i.
* Partition cÅ© **khÃ´ng bá»‹ xoÃ¡**; náº¿u cáº§n váº«n cÃ³ thá»ƒ Ä‘Æ°á»£c metadata má»›i tham chiáº¿u láº¡i.
* Partition chá»‰ **pruning á»Ÿ má»©c file**:

  * Iceberg kiá»ƒm tra file **cÃ³ kháº£ nÄƒng chá»©a value cáº§n tÃ¬m hay khÃ´ng**
  * CÃ³ â‡’ scan file Ä‘Ã³
  * KhÃ´ng â‡’ skip
* VÃ¬ váº­y thÆ°á»ng káº¿t há»£p thÃªm **sort / z-order / compaction** á»Ÿ má»©c datafile vÃ  table Ä‘á»ƒ tÄƒng hiá»‡u nÄƒng.

---

#### 3. LÆ°u Ã½
* Khi thay Ä‘á»•i partition khÃ¡c loáº¡i `(time/truncate/bucket)` thÃ¬ cáº§n drop partition cÅ©. NgÆ°á»£c láº¡i chá»‰ cáº§n add.

```sql
-- L1
CREATE TABLE catalog.members (...) PARTITIONED BY years(registration_ts) USING iceberg;

-- L2
ALTER TABLE catalog.members ADD PARTITION FIELD months(registration_ts)

-- L3
ALTER TABLE catalog.members DROP PARTITION FIELD bucket(24, id);
```

* Khi thá»±c hiá»‡n `compaction` sáº½ Ã¡p dá»¥ng Partition Plan má»›i nháº¥t. NÃªn add thÃªm option khi rewrite náº¿u muá»‘n ngÄƒn viá»‡c máº·c Ä‘á»‹nh chá»n Partition Plan má»›i nháº¥t.